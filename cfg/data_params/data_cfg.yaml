name: tim
/data_folder: ../data/raw/  #path of the dataset

# preprocessing

#whether to filter the items with low frequency
min_items_per_user: 0 #the minimum number of items rated by a user
min_users_per_item: 0 #the minimum number of users that have rated an item

densify_index: True #whether to densify the index of the dataset

split_keys:
      sid: [train_sid, val_sid, test_sid]
      timestamp: [train_timestamp, val_timestamp, test_timestamp]
      rating: [train_rating, val_rating, test_rating]

dataset_params:
  split_keys:
      train: [sid, uid, rating]
      val: [sid, uid, rating]
      test: [sid, uid, rating]

collator_params:
  sequential_keys: [sid, rating] #timestamp, rating #the sequential keys of the dataset
  padding_value: 0 #the padding value for the dataset
  lookback: 45 #1 for NCF and GCN #45 for SASRec, Caser, GRU4Rec
  lookforward: 1 #the lookforward of the dataset
  simultaneous_lookforward: 1 #the simultaneous lookforward of the dataset
  simultaneous_lookback: 45 #the simultaneous lookback of the dataset
  out_seq_len: # Number of predictions to keep (i.e. not masked as padding) --> to avoid train/test leakage
    train: null #the output sequence length of the training set
    val: &val_size 0.125 #the output sequence length of the validation set (after test split)
    test: &test_size 0.2 #the output sequence length of the test set
  num_negatives:
    train: 0
    val: 100
    test: 1.
  #possible_negatives: all #for testing
  negatives_relevance: 0
  relevance: out_rating

split_method: leave_n_out #the split method of the dataset, including 'leave_n_out', 'hold_out', 'k_fold'
test_sizes: [*test_size,*val_size] #"n" for leave_n_out the number of (positive) samples for each user in the test set